{
 "metadata": {
  "name": "",
  "signature": "sha256:1e2d229192415764e60d3ee1dd867a706e4aeb05639771f5d268bad495d5ad05"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import print_function\n",
      "#'positive'\n",
      "#strand = 'negative'\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn import cross_validation\n",
      "import numpy as np\n",
      "import csv\n",
      "from matplotlib import pyplot as plt\n",
      "from matplotlib.colors import ListedColormap\n",
      "import pandas as pd\n",
      "import sys\n",
      "from pandas import DataFrame, read_csv\n",
      "# Basic CSV IO\n",
      "import numpy as np\n",
      "from sklearn.cross_validation import train_test_split\n",
      "import matplotlib.pyplot as plt\n",
      "from matplotlib.colors import ListedColormap\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "from sklearn import preprocessing\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn import preprocessing\n",
      "from sklearn import svm\n",
      "from time import time\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.datasets import fetch_lfw_people\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.metrics import classification_report\n",
      "from sklearn.metrics import confusion_matrix\n",
      "from sklearn.decomposition import RandomizedPCA\n",
      "from sklearn.svm import SVC\n",
      "from collections import defaultdict\n",
      "import csv,sys,os,random,math,array,glob,re,time,timeit\n",
      "import logging\n",
      "import matplotlib.pyplot as plt\n",
      "from time import time\n",
      "from datetime import datetime\n",
      "\n",
      "#strand = sys.argv[1]\n",
      "strand='negative'\n",
      "\n",
      "chrm_len = {'Pf3D7_01_v3': 640851,'Pf3D7_02_v3': 947102, \n",
      "'Pf3D7_03_v3': 1067971,'Pf3D7_04_v3': 1200490,'Pf3D7_05_v3': 1343557,\n",
      "'Pf3D7_06_v3': 1418242,  'Pf3D7_07_v3': 1445207, 'Pf3D7_08_v3': 1472805,   \n",
      "'Pf3D7_09_v3': 1541735,'Pf3D7_10_v3': 1687656,'Pf3D7_11_v3': 2038340, \n",
      "'Pf3D7_12_v3': 2271494,'Pf3D7_13_v3': 2925236,  'Pf3D7_14_v3': 3291936,\n",
      "}\n",
      "\n",
      "def read_data(file_name):\n",
      "    f = open(file_name)\n",
      "    #ignore header\n",
      "    f.readline()\n",
      "    samples = []\n",
      "    target = []\n",
      "    for line in f:\n",
      "        line = line.strip().split(\",\")\n",
      "        sample = [float(x) for x in line]\n",
      "        samples.append(sample)\n",
      "    return samples\n",
      "\n",
      "def write_delimited_file(file_path, data,header=None, delimiter=\",\"):\n",
      "    f_out = open(file_path,\"w\")\n",
      "    if header is not None:\n",
      "        f_out.write(delimiter.join(header) + \"\\n\")\n",
      "    for line in data:\n",
      "        if isinstance(line, str):\n",
      "            f_out.write(line + \"\\n\")\n",
      "        else:\n",
      "            f_out.write(delimiter.join(line) + \"\\n\")\n",
      "    f_out.close()\n",
      "\n",
      "def read_csv(file_path, has_header = True):\n",
      "    with open(file_path) as f:\n",
      "        if has_header: f.readline()\n",
      "        data = []\n",
      "        for line in f:\n",
      "            line = line.strip().split(\",\")\n",
      "            data.append([float(x) for x in line])\n",
      "    return data\n",
      "\n",
      "def write_csv(file_path, data):\n",
      "    with open(file_path,\"w\") as f:\n",
      "        for line in data: f.write(\",\".join(line) + \"\\n\")\n",
      "def moving_average(a, n) :\n",
      "    ret = np.cumsum(a, dtype=float)\n",
      "    ret[n:] = ret[n:] - ret[:-n]\n",
      "    return ret[n - 1:] / n\n",
      "\n",
      "\n",
      "# find consecutive group > 50\n",
      "def group_consecutives(vals, step=1):\n",
      "    \"\"\"Return list of consecutive lists of numbers from vals (number list).\"\"\"\n",
      "    run = []\n",
      "    result = [run]\n",
      "    expect = None\n",
      "    for v in vals:\n",
      "        if (v == expect) or (expect is None):\n",
      "            run.append(v)\n",
      "        else:\n",
      "            run = [v]\n",
      "            result.append(run)\n",
      "        expect = v + step\n",
      "    return result\n",
      "############################3\n",
      "# import data #####\n",
      "#################\n",
      "if strand == 'positive':\n",
      "    File = '/Users/maggie/Desktop/TSS_Project_folder/Gene_v11/coordinateFiles/gene_start/1500bp/MargSize_50/sum_sequence/Positive_1500bp_gene_start_50_trainset_6000.seq.txt'\n",
      "elif strand == 'negative': \n",
      "    File = '/Users/maggie/Desktop/TSS_Project_folder/Gene_v11/coordinateFiles/gene_start/1500bp/MargSize_50/sum_sequence/Negative_1500bp_gene_start_50_trainset_6000.seq.txt'\n",
      "#Data = pd.read_csv(PosFile, index_col=-1,header=None,sep = ',')\n",
      "\n",
      "Data = pd.read_csv(File, index_col=-1,header=None,sep = ',')\n",
      "Data_label = Data.index\n",
      "Data_label.values[Data_label.values == 5]='0'\n",
      "Data_value = Data.values\n",
      "Data_target_label = Data.index.unique()\n",
      "scaler = preprocessing.StandardScaler().fit(Data_value)\n",
      "\n",
      "# No Normalization at all\n",
      "train_data = scaler.transform(Data_value)\n",
      "print (Data_target_label)\n",
      "############################3\n",
      "#trian for model\n",
      "############################3\n",
      "print('trianing model using file: ', File)\n",
      "print('strand:',strand)\n",
      "clf_rbf = svm.SVC(kernel = 'rbf', C=10, gamma=0.001, probability=True) \n",
      "clf_rbf.fit(train_data, Data_label)\n",
      "all_score = clf_rbf.score(train_data, Data_label)\n",
      "#y_pred_chrm = clf_rbf.predict(train_data)\n",
      "#y_pred_chrm_prob = clf_rbf.predict_proba(train_data)\n",
      "#Data_label=map(int, Data_label)\n",
      "#Data_label = np.asarray(Data_label)\n",
      "#print(classification_report(Data_label.astype(str), y_pred_chrm.astype(str) ))\n",
      "#print(confusion_matrix(Data_label.astype(str), y_pred_chrm.astype(str)))\n",
      "print (all_score,'\\n') #0.987\n",
      "print ('##################################################################')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[1 0]\n",
        "trianing model using file:  /Users/maggie/Desktop/TSS_Project_folder/Gene_v11/coordinateFiles/gene_start/1500bp/MargSize_50/sum_sequence/Negative_1500bp_gene_start_50_trainset_6000.seq.txt\n",
        "strand: negative\n",
        "0.987"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " \n",
        "\n",
        "##################################################################\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "seqFolder = '/Users/maggie/Desktop/TSS_Project_folder/scikit_learn/gene_start/seqFolder_1500bp/'\n",
      "os.chdir(seqFolder)\n",
      "seq_pattern = '*.test'\n",
      "result_folder='/Users/maggie/Desktop/TSS_Project_folder/scikit_learn/gene_start/Result_folder/test/'\n",
      "\n",
      "timestart = datetime.now().strftime(\"%Y%m%d-%H%M%S\")[:-2]\n",
      "#20141012-111738\n",
      "report = result_folder+ 'classification_report_genestarts_'+strand+'_'+timestart+'.txt'\n",
      "classification_report_out = open(report,'a')\n",
      "#print (report)\n",
      "print (timestart)\n",
      "classification_report_out.write(timestart+'\\n')\n",
      "\n",
      "\n",
      "#t0 = time()\n",
      "\n",
      "index = 0\n",
      "label_dict = []\n",
      "actual_label_list = []\n",
      "predicted_label_list = []\n",
      "for file in glob.glob(seq_pattern):\n",
      "    t0 = time()\n",
      "#print (file,timeNow)\n",
      "    \n",
      "    chrm = file.split('.')[0]\n",
      "    chrmFile = seqFolder+file\n",
      "    chrmFile_resulttableFile = result_folder+chrm+'_'+strand+'_'+timestart+'.table.txt'\n",
      "    #print(chrmFile)\n",
      "    \n",
      "    if not os.path.isfile(chrmFile_resulttableFile):\n",
      "        print ('START #############',chrm, strand,'####################################\\n')\n",
      "        print ('### readin data:',file,'###\\n')\n",
      "        #result_table = open(chrmFile_resulttableFile,'w')\n",
      "        classification_report_out.write('START ############# '+chrm+'---'+strand+' ####################################\\n')\n",
      "        classification_report_out.write('### readin data: '+file+' ###\\n')\n",
      "        \n",
      "        #import chromosme seq\n",
      "        chData = pd.read_csv(chrmFile, index_col=-1,header=None,iterator=True, chunksize=1000)\n",
      "        print (chData)\n",
      "        \n",
      "       \n",
      "         \n",
      "        \n",
      "        chData_target = chData.index\n",
      "        chData_target.values[chData_target.values == 'L1']='1'\n",
      "        chData_target.values[chData_target.values == 'L2']='2'\n",
      "        chData_target.values[chData_target.values == 'L3']='3'\n",
      "        chData_target.values[chData_target.values == 'L4']='4'\n",
      "        chData_target.values[chData_target.values == 'L5']='0'\n",
      "        chData_value = chData.values\n",
      "        chData_target_label = chData.index.unique()\n",
      "\n",
      "        \n",
      "        \n",
      "    \n",
      "        #preprocessing\n",
      "        print('### preprocessing/ mean normalization ###','\\n')\n",
      "        classification_report_out.write('### preprocessing/ mean normalization ###'+'\\n')\n",
      "        chrmtest_data =scaler.transform(chData_value)\n",
      "        \n",
      "        #print (chData_target_label)\n",
      "        print(\"### Predicting labels on ,\",chrm,'###\\n')\n",
      "        classification_report_out.write(\"### Predicting labels on ,\"+chrm+' ###\\n')\n",
      "        \n",
      "        # predict label\n",
      "        y_pred_chrm = clf_rbf.predict(chrmtest_data)\n",
      "\n",
      "        #y_pred_chrm_prob give probablility for each instance\n",
      "        y_pred_chrm_prob = clf_rbf.predict_proba(chrmtest_data)\n",
      "\n",
      "        #output result table \n",
      "        print ('### Output result table',chrmFile_resulttableFile,'###\\n' )\n",
      "        classification_report_out.write('### Output result table '+chrmFile_resulttableFile+' ###\\n' )\n",
      "        \n",
      "        result = pd.DataFrame(y_pred_chrm)\n",
      "        result_prob =  pd.DataFrame(y_pred_chrm_prob)\n",
      "        actual_label = pd.DataFrame(chData_target.values)\n",
      "        #if y_pred_chrm[0] == 1:\n",
      "         #   prob =\"%.3f\" % y_pred_chrm_prob[0][1]\n",
      "        #elif y_pred_chrm[0] == 0:\n",
      "          #  prob =\"%.3f\" % y_pred_chrm_prob[0][0]\n",
      "        \n",
      "        result['label'],result['prob0'], result['prob1'] = actual_label[0],result_prob[0], result_prob[1]\n",
      "        result.columns = ['predicted_label', 'old_label','probility_for_0','probility_for_1']\n",
      "        #print (y_pred_chrm[0] ,prob)\n",
      "        #result['label'],result['prob0'], result['prob1'] = actual_label[0],result_prob[0], result_prob[1]\n",
      "        #result['label'],result['probability'],result['chrm'] = actual_label[0],prob,chrm\n",
      "        #result.columns = ['predicted_label', 'actual_label','probability','chromosome']\n",
      "        result.to_csv(chrmFile_resulttableFile)\n",
      "        timeUsed = \"done in %0.3fs\" % (time() - t0)\n",
      "        #print(\"\\ndone in %0.3fs\" % (time() - t0),'\\n')\n",
      "        print(timeUsed+'\\n')        \n",
      "        print(classification_report(chData_target.values.astype(str), y_pred_chrm.astype(str) ))\n",
      "        print(confusion_matrix(chData_target.values.astype(str), y_pred_chrm.astype(str)))\n",
      "        \n",
      "        #classification_report_out.write('####################################################################\\n')\n",
      "        classification_report_out.write('\\n result statistic '+chrm+'--------'+strand+'--------\\n')\n",
      "        classification_report_out.write(classification_report(chData_target.values.astype(str), y_pred_chrm.astype(str) ))\n",
      "        classification_report_out.write('\\n')\n",
      "        classification_report_out.write(timeUsed+'\\n')\n",
      "        classification_report_out.write('####################################n')\n",
      "        print ('END ############',chrm, strand,'####################################\\n')\n",
      "        classification_report_out.write('End ############# '+chrm+'---'+strand+' ###################################\\n\\n')\n",
      "     \n",
      "     \n",
      "        '''\n",
      "classification_report_out.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "20141012-111738\n",
        "START ############# Pf3D7_01_v3 negative ####################################\n",
        "\n",
        "### readin data: Pf3D7_01_v3.label.txt.seq.txt.test ###\n",
        "\n",
        "### preprocessing/ mean normalization ###"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " \n",
        "\n",
        "### Predicting labels on ,"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Pf3D7_01_v3 ###\n",
        "\n",
        "### Output result table"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " /Users/maggie/Desktop/TSS_Project_folder/scikit_learn/gene_start/Result_folder/Pf3D7_01_v3_negative_20141012-111738.table.txt ###\n",
        "\n",
        "done in 41.709s\n",
        "\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.26      0.95      0.41       884\n",
        "          1       0.01      1.00      0.01        50\n",
        "          2       0.00      0.00      0.00      1450\n",
        "          3       0.00      0.00      0.00      7616\n",
        "\n",
        "avg / total       0.02      0.09      0.04     10000\n",
        "\n",
        "[[ 844   40    0    0]\n",
        " [   0   50    0    0]\n",
        " [   0 1450    0    0]\n",
        " [2428 5188    0    0]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "END ############ Pf3D7_01_v3 negative ####################################\n",
        "\n",
        "START ############# Pf3D7_02_v3 negative ####################################\n",
        "\n",
        "### readin data: Pf3D7_02_v3.label.txt.seq.txt.test ###\n",
        "\n",
        "### preprocessing/ mean normalization ###"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " \n",
        "\n",
        "### Predicting labels on ,"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Pf3D7_02_v3 ###\n",
        "\n",
        "### Output result table"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " /Users/maggie/Desktop/TSS_Project_folder/scikit_learn/gene_start/Result_folder/Pf3D7_02_v3_negative_20141012-111738.table.txt ###\n",
        "\n",
        "done in 41.329s\n",
        "\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       1.00      0.85      0.92     10000\n",
        "          1       0.00      0.00      0.00         0\n",
        "\n",
        "avg / total       1.00      0.85      0.92     10000\n",
        "\n",
        "[[8483 1517]\n",
        " [   0    0]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "END ############ Pf3D7_02_v3 negative ####################################\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "timestart = datetime.now().strftime(\"%Y%m%d-%H%M%S\")[:-2]\n",
      "\n",
      "timestart"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "'20141012-1131'"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "############################3\n",
      "# prediction #chunk by chunk\n",
      "############################3\n",
      "from time import time\n",
      "from pandas import *\n",
      "seqFolder = '/Users/maggie/Desktop/TSS_Project_folder/scikit_learn/gene_start/seqFolder_1500bp/'\n",
      "os.chdir(seqFolder)\n",
      "\n",
      "result_folder='/Users/maggie/Desktop/TSS_Project_folder/scikit_learn/gene_start/Result_folder/'\n",
      "timestart = datetime.now().strftime(\"%Y%m%d-%H%M%S\")[:-2]\n",
      "#20141012-111738\n",
      "report = result_folder+ 'classification_report_genestarts_'+strand+'_'+timestart+'.txt'\n",
      "classification_report_out = open(report,'a')\n",
      "#print (strand)\n",
      "\n",
      "seq_pattern = 'Pf3D7_01_v3.label.txt.seq.replaced.txt'\n",
      "result_array=['actual-label','predicted-label','score-0','score-1']\n",
      "\n",
      "for file in glob.glob(seq_pattern):\n",
      "    t0 = time()\n",
      "    index = 0\n",
      "    label_dict = []\n",
      "    actual_label_list = []\n",
      "    predicted_label_list = []\n",
      "    overall_list=[]\n",
      "    print (file)\n",
      "    chrm = file.split('.')[0]\n",
      "    chrmFile = seqFolder+file\n",
      "    chrmFile_resulttableFile = result_folder+chrm+'_'+strand+'_'+timestart+'.table.txt'\n",
      "    print(chrmFile)\n",
      "\n",
      "    if not os.path.isfile(chrmFile_resulttableFile):\n",
      "        print ('START #############',chrm, strand,'####################################\\n')\n",
      "        print ('### readin data:',file,'###\\n')\n",
      "        result_table = open(chrmFile_resulttableFile,'a')\n",
      "        classification_report_out.write('START ############# '+chrm+'---'+strand+' ####################################\\n')\n",
      "        classification_report_out.write('### readin data: '+file+' ###\\n')\n",
      "\n",
      "        #import chromosme seq\n",
      "        chData_file = pd.read_csv(chrmFile, index_col=-1,header=None,iterator=True, chunksize=500000)\n",
      "        for chData in chData_file:\n",
      "            chData_target = chData.index\n",
      "            chData_value = chData.values\n",
      "            chData_target_label = chData.index.unique()\n",
      "            timeUsed = \"done in %0.3fs\" % (time() - t0)\n",
      "            print(timeUsed+'\\n')\n",
      "            if strand == 'positive':\n",
      "                test_window = scaler.transform(chData_value)\n",
      "            elif strand == 'negative':\n",
      "                test_window = scaler.transform(chData_value[:,::-1])\n",
      "                \n",
      "            \n",
      "            \n",
      "            y_pred_chrm = clf_rbf.predict(test_window)\n",
      "            y_pred_chrm_prob = clf_rbf.predict_proba(test_window)\n",
      "            \n",
      "            columnbind =np.column_stack((chData_target,y_pred_chrm,y_pred_chrm_prob))  \n",
      "            result_array= np.vstack([result_array, columnbind])\n",
      "            #print(result_array)\n",
      "            actual_label_list.extend(np.asarray(chData_target))\n",
      "            predicted_label_list.extend(np.asarray(y_pred_chrm))\n",
      "            \n",
      "        result = pd.DataFrame(result_array[1:])\n",
      "        result.to_csv(chrmFile_resulttableFile)\n",
      "        print(classification_report(np.asarray(actual_label_list).astype(str),np.asarray(predicted_label_list).astype(str) ))\n",
      "        print(confusion_matrix(np.asarray(actual_label_list).astype(str), np.asarray(predicted_label_list).astype(str)))\n",
      "\n",
      "            \n",
      "        #classification_report_out.write('####################################################################\\n')\n",
      "        timeUsed = \"done in %0.3fs\" % (time() - t0)\n",
      "        classification_report_out.write('\\n result statistic '+chrm+'--------'+strand+'--------\\n')\n",
      "        classification_report_out.write(classification_report(np.asarray(actual_label_list).astype(str),np.asarray(predicted_label_list).astype(str) ))\n",
      "        classification_report_out.write('\\n')\n",
      "        classification_report_out.write(timeUsed+'\\n')\n",
      "        classification_report_out.write('####################################n')\n",
      "        print ('END ############',chrm, strand,'####################################\\n')\n",
      "        classification_report_out.write('End ############# '+chrm+'---'+strand+' ###################################\\n\\n')\n",
      "                \n",
      "            \n",
      "            \n",
      "classification_report_out.close()  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Pf3D7_01_v3.label.txt.seq.replaced.txt\n",
        "/Users/maggie/Desktop/TSS_Project_folder/scikit_learn/gene_start/seqFolder_1500bp/Pf3D7_01_v3.label.txt.seq.replaced.txt\n",
        "START ############# Pf3D7_01_v3 negative ####################################\n",
        "\n",
        "### readin data: Pf3D7_01_v3.label.txt.seq.replaced.txt ###\n",
        "\n",
        "done in 118.274s\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done in 14056.201s\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.20      0.97      0.33     77104\n",
        "          1       0.01      0.30      0.01      4357\n",
        "          2       0.00      0.00      0.00    124965\n",
        "          3       0.00      0.00      0.00    216033\n",
        "          4       0.00      0.00      0.00    159258\n",
        "\n",
        "avg / total       0.03      0.13      0.04    581717\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[[ 74567   2537      0      0      0]\n",
        " [  3051   1306      0      0      0]\n",
        " [ 86459  38506      0      0      0]\n",
        " [102060 113973      0      0      0]\n",
        " [110101  49157      0      0      0]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "END ############"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Pf3D7_01_v3 negative ####################################\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "//anaconda/lib/python2.7/site-packages/sklearn/metrics/metrics.py:1905: UserWarning: The sum of true positives and false positives are equal to zero for some labels. Precision is ill defined for those labels ['2' '3' '4']. The precision and recall are equal to zero for some labels. fbeta_score is ill defined for those labels ['2' '3' '4']. \n",
        "  average=None)\n"
       ]
      }
     ],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(classification_report(np.asarray(actual_label_list).astype(str),np.asarray(predicted_label_list).astype(str) ))\n",
      "print(confusion_matrix(np.asarray(actual_label_list).astype(str), np.asarray(predicted_label_list).astype(str)))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.24      0.92      0.38       884\n",
        "          1       0.01      1.00      0.01        50\n",
        "          2       0.00      0.00      0.00      1450\n",
        "          3       0.00      0.00      0.00      7616\n",
        "\n",
        "avg / total       0.02      0.09      0.03     10000\n",
        "\n",
        "[[ 815   69    0    0]\n",
        " [   0   50    0    0]\n",
        " [  49 1401    0    0]\n",
        " [2507 5109    0    0]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chData_target[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 50,
       "text": [
        "3"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "columnbind"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "array([[ 3.        ,  0.        ,  0.83419312,  0.16580688],\n",
        "       [ 3.        ,  0.        ,  0.83184863,  0.16815137],\n",
        "       [ 3.        ,  0.        ,  0.83112804,  0.16887196],\n",
        "       ..., \n",
        "       [ 5.        ,  0.        ,  0.91401301,  0.08598699],\n",
        "       [ 5.        ,  0.        ,  0.91401301,  0.08598699],\n",
        "       [ 5.        ,  0.        ,  0.91401301,  0.08598699]])"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_pred_chrm[0:100]\n",
      "append[0:100]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 0, 0, 0, 0])"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "T = A - B\n",
      "max = numpy.max(numpy.abs(T))\n",
      "\n",
      "epsilon = 1e-6\n",
      "if max > epsilon:\n",
      "    raise Exception(\"Not matching arrays\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "array([   0.,    0.,    0., ...,  105.,  105.,  110.])"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_pred_chrm_prob"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "0"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "############################3\n",
      "# prediction #line by line\n",
      "############################3\n",
      "seqFolder = '/Users/maggie/Desktop/TSS_Project_folder/scikit_learn/gene_start/seqFolder_1500bp/'\n",
      "os.chdir(seqFolder)\n",
      "\n",
      "result_folder='/Users/maggie/Desktop/TSS_Project_folder/scikit_learn/gene_start/Result_folder/'\n",
      "\n",
      "report = result_folder+'classification_report_'+strand+'.txt'\n",
      "classification_report_out = open(report,'a')\n",
      "#print (strand)\n",
      "from time import time\n",
      "#t0 = time()\n",
      "\n",
      "seq_pattern = '*.seq.txt'\n",
      "\n",
      "\n",
      "for file in glob.glob(seq_pattern):\n",
      "    t0 = time()\n",
      "    index = 0\n",
      "    label_dict = []\n",
      "    actual_label_list = []\n",
      "    predicted_label_list = []\n",
      "    print (file)\n",
      "    chrm = file.split('.')[0]\n",
      "    chrmFile = seqFolder+file\n",
      "    chrmFile_resulttableFile = result_folder+chrm+'.'+strand+'.table.bed'\n",
      "    #print(chrmFile)\n",
      "    if not os.path.isfile(chrmFile_resulttableFile):\n",
      "        print('creating file:',chrmFile_resulttableFile )\n",
      "        result_table = open(chrmFile_resulttableFile,'w')\n",
      "        with open (chrmFile, 'r') as ChrmIn:#pd.read_csv(chrmFile, index_col=-1,header=None) as chrmIn:\n",
      "            for line in ChrmIn:\n",
      "                index = index +1\n",
      "                fi = line.strip().split(',')\n",
      "                chrm_window = map(float, fi[0:1500])\n",
      "            #test_window = scaler.transform(chrm_window)\n",
      "                if strand == 'positive':\n",
      "                    test_window = scaler.transform(chrm_window)\n",
      "                elif strand == 'negative':\n",
      "                    test_window = scaler.transform(chrm_window)[::-1]\n",
      "            #test_window = scaler.fit(chrm_window).transform(chrm_window)\n",
      "                if fi[-1] == 'L5':\n",
      "                    actual_label = 0 #fi[-1].replace('5', '0')            \n",
      "                else:\n",
      "                    actual_label= int(fi[-1][-1])\n",
      "                actual_label_list.append(actual_label)\n",
      "            #prediction\n",
      "                y_pred_chrm = clf_rbf.predict(test_window)\n",
      "                y_pred_chrm_prob = clf_rbf.predict_proba(test_window)\n",
      "                predicted_label_list.append(y_pred_chrm[0])\n",
      "                if y_pred_chrm[0] == 1:\n",
      "                    prob =\"%.3f\" % y_pred_chrm_prob[0][1]\n",
      "                elif y_pred_chrm[0] == 0:\n",
      "                    prob =\"%.3f\" % y_pred_chrm_prob[0][0]\n",
      "        \n",
      "                label_dict.append([chrm,index,actual_label,y_pred_chrm[0],prob,'\\n'])\n",
      "                labelList=[chrm,str(index),str(actual_label),str(y_pred_chrm[0]),str(prob),'\\n']\n",
      "                label_dict_seq = '\\t'.join(labelList)\n",
      "                result_table.write(label_dict_seq)\n",
      "    # report \n",
      "        print ('listlen:',len(actual_label_list))\n",
      "        print(classification_report(np.asarray(actual_label_list).astype(str),np.asarray(predicted_label_list).astype(str) ))\n",
      "        print(confusion_matrix(np.asarray(actual_label_list).astype(str), np.asarray(predicted_label_list).astype(str)))\n",
      "        classification_report_out.write(classification_report(np.asarray(actual_label_list).astype(str),np.asarray(predicted_label_list).astype(str) ))\n",
      "        classification_report_out.write(confusion_matrix(np.asarray(actual_label_list).astype(str), np.asarray(predicted_label_list).astype(str)))\n",
      "        classification_report_out.write('####################################################################\\n')\n",
      "        classification_report_out.write(chrm+'--------'+strand+'--------')\n",
      "        classification_report_out.write(classification_report(np.asarray(actual_label_list).astype(str),np.asarray(predicted_label_list).astype(str) ))\n",
      "        classification_report_out.write('\\n')\n",
      "    #classification_report_out.write(confusion_matrix(np.asarray(actual_label_list).astype(str), np.asarray(predicted_label_list).astype(str)))\n",
      "        classification_report_out.write('\\n')\n",
      "        classification_report_out.write('####################################################################\\n')\n",
      "        print(\"done in %0.3fs\" % (time() - t0))\n",
      "    \n",
      "        result_table.close()\n",
      "    \n",
      "\n",
      "    classification_report_out.close()\n",
      "'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[1 0]\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}